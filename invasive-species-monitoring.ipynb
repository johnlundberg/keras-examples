{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T20:42:00.593816Z",
     "start_time": "2017-09-24T20:42:00.565744Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import math, os, datetime, random, shutil\n",
    "import numpy as np\n",
    "from numpy.random import permutation\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as kb\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Lambda, Dense, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LambdaCallback\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize data\n",
    "\n",
    "Data used is from kaggle competition invaisive species monitoring.\n",
    "https://www.kaggle.com/c/invasive-species-monitoring\n",
    "\n",
    "By organising data in different folders for different classes, keras parses the classes from the folder hierarchy.\n",
    "\n",
    "Data was divided into subdirectories for training, validation and test data.\n",
    "\n",
    "Folder tree:\n",
    "```\n",
    "data\n",
    "    train\n",
    "        invasive\n",
    "        non-invasive\n",
    "    valid\n",
    "        invasive\n",
    "        non-invasive\n",
    "    test\n",
    "        unknown\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T20:42:03.333450Z",
     "start_time": "2017-09-24T20:42:03.325438Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataPath = 'data/'\n",
    "modelPath = 'data/models/'\n",
    "imageSize = (512,512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T20:42:04.584811Z",
     "start_time": "2017-09-24T20:42:04.563235Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch size can be increased if GPU memory can take it.\n",
    "batch_size = 12\n",
    "\n",
    "# Keras ImageDataGenerator class modifies the images in different random ways so that the same image is never seen twice.\n",
    "# That way there is more data to learn from.\n",
    "\n",
    "def getTrainingDataGenerator():\n",
    "    return ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        channel_shift_range=0.1,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "# flow_from_directory iterates the directory structure and returns batches of images \n",
    "# with the class name parsed from the directory.\n",
    "def getTrainingDataBatches():\n",
    "    return getTrainingDataGenerator().flow_from_directory(\n",
    "        dataPath + 'train', \n",
    "        target_size=imageSize,\n",
    "        class_mode='binary', \n",
    "        shuffle=True, \n",
    "        batch_size=batch_size)\n",
    "\n",
    "def getValidationDataBatches(): \n",
    "    return ImageDataGenerator().flow_from_directory(\n",
    "        dataPath + 'valid', \n",
    "        target_size=imageSize, \n",
    "        class_mode='binary', \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False)\n",
    "\n",
    "def getTestDataBatches():\n",
    "    return  ImageDataGenerator().flow_from_directory(\n",
    "        dataPath + 'test/', \n",
    "        target_size=imageSize,\n",
    "        class_mode=None,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T20:44:05.318834Z",
     "start_time": "2017-09-24T20:44:05.236049Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addConvLayer(m, filterCount):\n",
    "    m.add(ZeroPadding2D((1,1)))\n",
    "    m.add(Conv2D(filterCount,(3,3), activation='relu'))\n",
    "    m.add(BatchNormalization(axis=1))\n",
    "    \n",
    "def addConvBlock(m, filterCount, layerCount):\n",
    "    for i in range(layerCount):\n",
    "        addConvLayer(m, filterCount)\n",
    "    m.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "def addDenseLayer(m, nodeCount, dropout):\n",
    "    m.add(Dense(nodeCount,activation='relu'))\n",
    "    m.add(Dropout(dropout))\n",
    "    m.add(BatchNormalization())\n",
    "\n",
    "def build(dropout):\n",
    "    input_shape = (imageSize[0], imageSize[1],3)\n",
    "    m = Sequential()\n",
    "\n",
    "    # By applying BatchNormalization as the first layer the input data is automatically normalized.\n",
    "    m.add(BatchNormalization(axis=1,input_shape=input_shape))\n",
    "\n",
    "    # To handle the larger image sizes I had to apply a larger conv layer on the input data, with a bigger stride.\n",
    "    m.add(ZeroPadding2D((1,1)))\n",
    "    m.add(Conv2D(32,(5,5),strides=(2,2), activation='relu'))    \n",
    "    m.add(MaxPooling2D((3,3), strides=(2,2)))\n",
    "    m.add(BatchNormalization(axis=1))\n",
    "    \n",
    "    # The rest of the conv layers are 3x3 with a regular 1 step stride.\n",
    "    addConvBlock(m, 64, 2)\n",
    "    addConvBlock(m, 128, 2)\n",
    "    addConvBlock(m, 256, 2)\n",
    "    addConvBlock(m, 512, 2)\n",
    "    \n",
    "    m.add(Flatten())\n",
    "\n",
    "    addDenseLayer(m, 1024, dropout)\n",
    "    addDenseLayer(m, 1024, dropout)\n",
    "    \n",
    "    m.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Help methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T20:44:06.224630Z",
     "start_time": "2017-09-24T20:44:06.170301Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(m, test_batches):\n",
    "    return m.predict_generator(test_batches, test_batches.nb_sample) \n",
    "\n",
    "def getDateTimeString():\n",
    "    return datetime.datetime.now().strftime(\"%Y-%m-%d.%H-%M-%S\")\n",
    "\n",
    "def fitGenerator(m, lr, nb_epoch):\n",
    "    m.compile(optimizer=Adam(lr=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    trainBatches = getTrainingDataBatches()\n",
    "    valBatches = getValidationDataBatches()\n",
    "        \n",
    "    return m.fit_generator(\n",
    "        trainBatches,\n",
    "        samples_per_epoch=trainBatches.nb_sample, \n",
    "        nb_epoch=nb_epoch,\n",
    "        validation_data=valBatches,\n",
    "        nb_val_samples=valBatches.nb_sample,\n",
    "        verbose=2,\n",
    "        callbacks=[TQDMNotebookCallback()])\n",
    "\n",
    "def plotAllHistory(history):\n",
    "    plotAccHistory(history)\n",
    "    plotLossHistory(history)\n",
    "\n",
    "def plotLossHistory(history):\n",
    "    plotHistory(history, 'loss', 'Loss')\n",
    "\n",
    "def plotAccHistory(history):\n",
    "    plotHistory(history, 'acc', 'Accuracy')\n",
    "    \n",
    "def plotHistory(history, metric, metricFullName):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_' + metric])\n",
    "    plt.title(metricFullName)\n",
    "    plt.ylabel(metricFullName)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T20:44:08.265231Z",
     "start_time": "2017-09-24T20:44:07.164357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_5 (Batch (None, 512, 512, 3)       2048      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 514, 514, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 255, 255, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 127, 127, 32)      508       \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 129, 129, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 127, 127, 64)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 127, 127, 64)      508       \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 129, 129, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 127, 127, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 127, 127, 64)      508       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 65, 65, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 63, 63, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 63, 63, 128)       252       \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 65, 65, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 63, 63, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 63, 63, 128)       252       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 31, 31, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 31, 31, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 31, 31, 256)       124       \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 33, 33, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 31, 31, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 31, 31, 256)       124       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 15, 15, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 15, 15, 512)       60        \n",
      "_________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPaddi (None, 17, 17, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 15, 15, 512)       60        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 31,458,909\n",
      "Trainable params: 31,452,591\n",
      "Non-trainable params: 6,318\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build(dropout=0.1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T20:44:21.434870Z",
     "start_time": "2017-09-24T20:44:21.348544Z"
    }
   },
   "outputs": [],
   "source": [
    "history = fitGenerator(model, lr=0.001, nb_epoch=20)\n",
    "plotAllHistory(history)\n",
    "model.load_weights(modelPath + 'model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T20:47:05.233975Z",
     "start_time": "2017-09-24T20:47:05.217955Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFileIndices():\n",
    "    return [int(x.split('\\\\')[1].split('.')[0]) for x in getTestDataBatches().filenames]\n",
    "\n",
    "def combineIndicesWithPredictions(fileIdxs, preds):\n",
    "    combined = np.column_stack((fileIdxs, preds))\n",
    "    combined = combined[combined[:,0].argsort()]\n",
    "    return combined;\n",
    "    \n",
    "def writePredictionsToFile(preds, predictionsPath):\n",
    "    np.savetxt(\n",
    "        predictionsPath, \n",
    "        preds,\n",
    "        fmt ='%1.1d, %1.2f',\n",
    "        header='name,invasive', \n",
    "        comments='') #'id,label', "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for submitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T08:30:24.560000Z",
     "start_time": "2017-08-15T08:30:24.392000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1531 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = getTestDataBatches()\n",
    "predictions = predict(model, test_batches)\n",
    "fileIdxs = getFileIndices()\n",
    "combined = combineIndicesWithPredictions(fileIdxs, predictions)\n",
    "writePredictionsToFile(combined, data + 'predictions/predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {
    "height": "479px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {
    "029a53fef4ee4823aa2038fe6559ce0c": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "04ba7e2696524d039827a5741c33d231": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "078a29303b984148a5f952d3e1d675f6": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "09b9266957d54f1c8c7de5389b7e133b": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "0e5531b5e3854ec7806501c88bf1444a": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "10b96ed1cff9412192c1d6dd4eddbab6": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "1232f167a2ba47cd8c603465b0e4ae15": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "14a29b0d61fd4b8aaa0d8353e6d9a7f4": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "17a2550faea349b1b1996bcd16e54671": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "19ece358a99f42aab26128cb9f36680e": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "1b8a6c3aebd0416989c488ddc2abd00e": {
     "views": [
      {
       "cell_index": 21
      }
     ]
    },
    "1d04af794be6487aa692f1a0afee2759": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "1ee540b7ea7b41559690aa1c68f95bd0": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "2329c1eb4ed14a6c97e52e8b7aaba1c4": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "25a066bb2f7b4ebebcf8a7954274270c": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "2ea424546d3a434a87619ac45ab39322": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "2fcc6dfefc4948b1941ec4cf71e93702": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "31f6a25f316f4f1281bc0d7e8b760113": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "3801e02d0cb04fbdb059851c72a9fe5c": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "383e7d588ad5426b9a7ceac9a9a0dbf1": {
     "views": [
      {
       "cell_index": 21
      }
     ]
    },
    "3b2096dc03724a3da469aaf5a70f7ad0": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "3fc0136264134bf7b8af7d292f1f500a": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "42ddcf411a3c4a2798ca02a232674318": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "42ff0f43b04043958633026b792a65cf": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "430e62838f3441aea9347d31fd146ec9": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "4330929ede5b4c71b33cf13ecd47966d": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "474ef70dc0634764b0642430178b63dc": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "4bac45cf44a14298b24f175d642c3351": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "4e251323cc3e465ebeb9293f81b0c4d1": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "5276fe04d5ab4a77a4af63b42373d87b": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "5a0629bc5e26430782c7527c2e42927d": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "5c81e2faca654d16934f4123f2902bfc": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "5c872d3e388349fc8536178e9bffcefa": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "5e2eda5b40144ec299ddb663cb5cbb06": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "67fdb0cb5799459fb2219fbb21e96ba4": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "6911744c63fe407c8536fff0377c1380": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "6bad1db511e04d7aaf68acaa05a4eb51": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "6d0d91e40b674834b7d4e9978485bdb9": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "76563b1d6c2e4aa9bb3be59676e44c05": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "77753e67014d4950b8d7ce7a44e23e04": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "7c4167fdd42e4cbb80d6343ba6293b2b": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "7da68d2aae5642aba22b9aa455d1bd3a": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "828bf80df62349feb15c69f2452d7bc1": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "8903b9fdd416467798cc4adea218dd5e": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "8abb2ebf5eef4c97b6b0bfac1676f09a": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "8c4ae65316c54d998f4189342346b927": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "8df1f506605e423c8e57a2631b456c16": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "8e0f1c34432b4becbc19db70fb37f7ed": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "8e7879e0f359431486660ad2f16ce0f9": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "92037b716311484d8ede8edab91f2556": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "97ac50f734664f0ba297968bcf5c0681": {
     "views": [
      {
       "cell_index": 21
      }
     ]
    },
    "99944545cd204fa497e28402d078f9b3": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "9e7aff6133924a97a9be67e94dd949f5": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "a0b602c313124867a15f86a37a96ab77": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "a0fe9fad0526419fb0c0f11b93b172cb": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "a6e2c6d20a674eba98398e86014ef6ea": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "a906898c9681442da4d04b15add0b51f": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "aecd6febf65143ed8e7c41b5e93fead1": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "af28642978c846eb9601fdae486981a5": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "b6774c60730e4c4793914b7690df4c66": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "b77ffd3ac22f4cca88d5d0cab93b193c": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "b7f721168fc140e6adce6220abd88d04": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "bcf6f987dfc141a088c8bd1c04a355ff": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "bfb41fc7efdb45fa9bfd5f5ff394d1f4": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "cc718dc4339244ca9c5facd28f98393b": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "ccfaf996351f4bebac8840f7326cfe1c": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "cdcc3773d4634a17a9f5598273d38c7a": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "cdff38dbdb1a4d6cbe7139af873e337c": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "ce2b78612f534e508feb47b74e680066": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "cf2be3a7505e47b2a21a37e76ac722be": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "d2d27acf380c49d7a298c6b06520e650": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "d4e1d0d80fc84d309f44dcddb5b301ab": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "d7c6807ee31349f69be4ac08785475bf": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "d7fe2e15e7b34b8bb67f53728626fa82": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "da6c50e4b7a047609ff93a0771ed53fe": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "de096115e5f1428fb99a3ce30fc0f502": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "de6fcc63abc84d4b9aa5ca67c545af57": {
     "views": [
      {
       "cell_index": 21
      }
     ]
    },
    "e31bb119ced0478caee6bad55df0f107": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "e3b434bad143460ca38a2c548f7fb422": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "e77cb2bedf734f0a999ab4829ec77ef0": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "e893540f65bd40bcaaaf0bc2e4dc5eaf": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "eaf2d7f82a8448b8bf0a9fb52d8f87c6": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "f03da871d6274e229187dee362d1fc59": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "f3c7a0ebcc5e40e5a0f90aadca8b31a2": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "f4fa1740c4e84c2ebded9ca99fb65ce1": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
